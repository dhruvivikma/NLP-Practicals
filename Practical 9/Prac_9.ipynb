{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prac_9.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHvx-PJ5o0hE"
      },
      "source": [
        "PRACTICAL 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KymcaPivo2V7",
        "outputId": "c8a6d511-66ed-4d33-8d0a-3b82062bc885"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_graphs(history, metric):\n",
        "  plt.plot(history.history[metric])\n",
        "  plt.plot(history.history['val_'+metric], '')\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(metric)\n",
        "  plt.legend([metric, 'val_'+metric])\n",
        "dataset, info = tfds.load('imdb_reviews', with_info=True,\n",
        "                          as_supervised=True)\n",
        "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
        "\n",
        "train_dataset.element_spec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mDownloading and preparing dataset imdb_reviews/plain_text/1.0.0 (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\u001b[0m\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incomplete5WRYGG/imdb_reviews-train.tfrecord\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incomplete5WRYGG/imdb_reviews-test.tfrecord\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incomplete5WRYGG/imdb_reviews-unsupervised.tfrecord\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Dataset is using deprecated text encoder API which will be removed soon. Please use the plain_text version of the dataset and migrate to `tensorflow_text`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mDataset imdb_reviews downloaded and prepared to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int64, name=None))"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onLVj-jlpqjI",
        "outputId": "74704c0c-f06c-49b3-8bd8-08cfb35d99d7"
      },
      "source": [
        "for example, label in train_dataset.take(1):\n",
        "  print('text: ', example.numpy())\n",
        "  print('label: ', label.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text:  b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"\n",
            "label:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxsL6PzTpu7Y",
        "outputId": "c87ebb6a-dbef-45d8-e305-8b7783525a66"
      },
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "for example, label in train_dataset.take(1):\n",
        "  print('texts: ', example.numpy()[:3])\n",
        "  print()\n",
        "  print('labels: ', label.numpy()[:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "texts:  [b'I voted 3 for this movie because it looks great as does all of Greenaways output. However it was his usual mix of \"art\" sex and pretentious crap.I know lots of people like this film but I grew tired of it VERY quickly. It is definitely not for everyone. The ubiquitous McGregor obviously took the part for crediblity\\'s sake I guess but he really should not have wasted his time. I hate to consign anyone to pseud\\'s corner but please.....!!! On the plus side it IS visually very attractive and I enjoyed the music but could not see it through to the end and I cannot say that for many movies. I usually watch the whole thing but this is unbearable!!'\n",
            " b'This film is fun, if your a person who likes a good campy feature film every now and then. By no means is this movie fine cinema, but if you dont take things too seriously, and can laugh at yourself once in a while, Elvira is a good frownbuster.'\n",
            " b'If you \"get it\", it\\'s magnificent.<br /><br />If you don\\'t, it\\'s decent.<br /><br />Please understand that \"getting it\" does not necessarily mean you\\'ve gone through a school shooting. There is so much more to this movie that, at times, the school shooting becomes insignificant.<br /><br />Above all, it\\'s a movie about acceptance, both superficially--of a traumatic event, but also of people who are different for whatever reason.<br /><br />It\\'s also a movie about unendurable pain, and how different people endure it. In this case, the contrast between Alicia\\'s rage and Deanna\\'s obsession creates an atmosphere of such palpable anxiety that halfway through the movie we wonder how the director could possibly pull a happy ending out of his hat. Thankfully, the audience is given credit for being human beings; our intelligence is not insulted by a sappy, implausibly moralistic ending.<br /><br />Above and beyond that, I try to keep a clear head about movies being fiction and all that. Yet I must admit, I cried like a lost little baby during this movie. There were certain things about it that hit *very* close to home and opened up some old wounds that never quite healed. But that is not necessarily a bad thing.']\n",
            "\n",
            "labels:  [0 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTQLj9g0pxni",
        "outputId": "e33bc5e9-16aa-4379-df4e-eafecbd7e65d"
      },
      "source": [
        "VOCAB_SIZE = 1000\n",
        "encoder = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE)\n",
        "encoder.adapt(train_dataset.map(lambda text, label: text))\n",
        "\n",
        "vocab = np.array(encoder.get_vocabulary())\n",
        "vocab[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['', '[UNK]', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it', 'i',\n",
              "       'this', 'that', 'br', 'was', 'as', 'for', 'with', 'movie', 'but'],\n",
              "      dtype='<U14')"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DubDGX3Cp0sK",
        "outputId": "2444a93b-4064-4289-fd81-3b7524e7c593"
      },
      "source": [
        "encoded_example = encoder(example)[:3].numpy()\n",
        "encoded_example"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 10,   1, 442, ...,   0,   0,   0],\n",
              "       [ 11,  20,   7, ...,   0,   0,   0],\n",
              "       [ 45,  23,  76, ...,   0,   0,   0]])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taQUIYJlp3jL",
        "outputId": "6061cb92-c3c2-4c01-88cc-50f633f7e7ba"
      },
      "source": [
        "for n in range(3):\n",
        "  print(\"Original: \", example[n].numpy())\n",
        "  print(\"Round-trip: \", \" \".join(vocab[encoded_example[n]]))\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  b'I voted 3 for this movie because it looks great as does all of Greenaways output. However it was his usual mix of \"art\" sex and pretentious crap.I know lots of people like this film but I grew tired of it VERY quickly. It is definitely not for everyone. The ubiquitous McGregor obviously took the part for crediblity\\'s sake I guess but he really should not have wasted his time. I hate to consign anyone to pseud\\'s corner but please.....!!! On the plus side it IS visually very attractive and I enjoyed the music but could not see it through to the end and I cannot say that for many movies. I usually watch the whole thing but this is unbearable!!'\n",
            "Round-trip:  i [UNK] 3 for this movie because it looks great as does all of [UNK] [UNK] however it was his usual [UNK] of art sex and [UNK] [UNK] know lots of people like this film but i [UNK] [UNK] of it very quickly it is definitely not for everyone the [UNK] [UNK] obviously took the part for [UNK] [UNK] i guess but he really should not have [UNK] his time i hate to [UNK] anyone to [UNK] [UNK] but please on the plus side it is [UNK] very [UNK] and i enjoyed the music but could not see it through to the end and i cannot say that for many movies i usually watch the whole thing but this is [UNK]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
            "\n",
            "Original:  b'This film is fun, if your a person who likes a good campy feature film every now and then. By no means is this movie fine cinema, but if you dont take things too seriously, and can laugh at yourself once in a while, Elvira is a good frownbuster.'\n",
            "Round-trip:  this film is fun if your a person who [UNK] a good [UNK] feature film every now and then by no means is this movie fine cinema but if you dont take things too seriously and can laugh at yourself once in a while [UNK] is a good [UNK]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
            "\n",
            "Original:  b'If you \"get it\", it\\'s magnificent.<br /><br />If you don\\'t, it\\'s decent.<br /><br />Please understand that \"getting it\" does not necessarily mean you\\'ve gone through a school shooting. There is so much more to this movie that, at times, the school shooting becomes insignificant.<br /><br />Above all, it\\'s a movie about acceptance, both superficially--of a traumatic event, but also of people who are different for whatever reason.<br /><br />It\\'s also a movie about unendurable pain, and how different people endure it. In this case, the contrast between Alicia\\'s rage and Deanna\\'s obsession creates an atmosphere of such palpable anxiety that halfway through the movie we wonder how the director could possibly pull a happy ending out of his hat. Thankfully, the audience is given credit for being human beings; our intelligence is not insulted by a sappy, implausibly moralistic ending.<br /><br />Above and beyond that, I try to keep a clear head about movies being fiction and all that. Yet I must admit, I cried like a lost little baby during this movie. There were certain things about it that hit *very* close to home and opened up some old wounds that never quite healed. But that is not necessarily a bad thing.'\n",
            "Round-trip:  if you get it its [UNK] br if you dont its [UNK] br please understand that getting it does not [UNK] mean youve gone through a school [UNK] there is so much more to this movie that at times the school [UNK] becomes [UNK] br above all its a movie about [UNK] both [UNK] a [UNK] [UNK] but also of people who are different for whatever [UNK] br its also a movie about [UNK] [UNK] and how different people [UNK] it in this case the [UNK] between [UNK] [UNK] and [UNK] [UNK] [UNK] an atmosphere of such [UNK] [UNK] that [UNK] through the movie we wonder how the director could possibly [UNK] a happy ending out of his [UNK] [UNK] the audience is given [UNK] for being human [UNK] our [UNK] is not [UNK] by a [UNK] [UNK] [UNK] [UNK] br above and beyond that i try to keep a clear head about movies being [UNK] and all that yet i must admit i [UNK] like a lost little baby during this movie there were certain things about it that hit very close to home and [UNK] up some old [UNK] that never quite [UNK] but that is not [UNK] a bad thing                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9r63Kf0p7je",
        "outputId": "146cd598-141b-4a44-f3e9-6f3d19dcc4aa"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=64,\n",
        "        # Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "print([layer.supports_masking for layer in model.layers])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[False, True, True, True, True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKg2KV0op_Si",
        "outputId": "68731fb8-9e29-4134-e74b-6745acf89238"
      },
      "source": [
        "sample_text = ('The movie was cool. The animation and the graphics '\n",
        "               'were out of this world. I would recommend this movie.')\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "print(predictions[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.00045438]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-m_nYA7qCq8",
        "outputId": "87c21dd3-36b2-4f4e-9b30-e01bab6018e6"
      },
      "source": [
        "padding = \"the \" * 2000\n",
        "predictions = model.predict(np.array([sample_text, padding]))\n",
        "print(predictions[0]) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.00045438]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1NcuounqFL2",
        "outputId": "35c0f9f5-2ce2-42a1-8834-4d6488eed938"
      },
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(train_dataset, epochs=3,\n",
        "                    validation_data=test_dataset,\n",
        "                    validation_steps=30)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "391/391 [==============================] - 737s 2s/step - loss: 0.6399 - accuracy: 0.5750 - val_loss: 0.5144 - val_accuracy: 0.6875\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 727s 2s/step - loss: 0.4407 - accuracy: 0.7824 - val_loss: 0.3900 - val_accuracy: 0.8141\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 722s 2s/step - loss: 0.3616 - accuracy: 0.8387 - val_loss: 0.3621 - val_accuracy: 0.8297\n",
            "391/391 [==============================] - 162s 414ms/step - loss: 0.3510 - accuracy: 0.8342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kE1vxXBxqNh8",
        "outputId": "e78edb07-d257-4045-d4fa-0c5840dc2fff"
      },
      "source": [
        "print('Test Loss:', test_loss)\n",
        "print('Test Accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.3510308861732483\n",
            "Test Accuracy: 0.8342400193214417\n"
          ]
        }
      ]
    }
  ]
}